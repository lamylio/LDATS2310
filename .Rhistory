predict(model.hurdle.2, type="response")[1:10]
range(predict(model.hurdle.2, type="response"))
rootogram(model.hurdle.2)
model.hurdle.2 = pscl::hurdle(formule.long.offset, data=base_train, dist="negbin", zero.dist = "geometric")
range(predict(model.hurdle.2, type="response"))
rootogram(model.hurdle.2)
customDeviance(model.hurdle.2)
customDeviance(model.hurdle.1)
customDeviance(predict(model.hurdle.1, type="response"))
customDeviance(predict(model.hurdle.1))
customDeviance = function(fitt){
y = base_train_freq$Frequency
w = base_train$Exposure
left = y * log(y) - y * log(fitt)
right = y - fitt
left[y==0] = 0 # Replace NA's by 0 because log(0) is -Inf but 0*Inf ~ 0
return(2*sum(w*(left-right)))
}
customDeviance(predict(model.hurdle.1))
customDeviance(predict(model.hurdle.2, type="response"))
customDeviance(predict(model.nb.1, type="response"))
customDeviance(predict(model.nb.2, type="response"))
customDeviance(predict(model.forest.class), type="response"))
customDeviance(predict(model.glm.1), type="response"))
customDeviance(predict(model.glm.1, type="response"))
customDeviance(predict(model.tree.1, type="response"))
customDeviance(predict(model.tree.1))
predict(model.tree.1)
range(predict(model.tree.1)-
range(predict(model.tree.1))
)
range(predict(model.tree.1))
model.gam.1 = gam(
Nbclaims ~ s(DriverAge, bs="cr", by = Gender) + Power+Gender+Area+Leasing+Fract,
data = base_train,
family=poisson(),
offset = log(Exposure),
method = "REML"
)
model.gam.1 = gam(
Nbclaims ~ s(DriverAge, bs="cr", by = Gender) + Power+Gender+Area+Leasing+Fract,
data = base_train,
family=poisson(),
offset = log(Exposure),
method = "REML"
)
model.gam.2 = gam(Nbclaims ~ s(DriverAge, by=Gender) + s(CarAge) +Power+Gender+Area+Leasing+Fract,
data = base_train,
family=poisson(),
offset=log(Exposure),
method = "REML"
)
model.gam.3 = gam(
Nbclaims ~ s(DriverAge, bs="cr", k=6) + Power+Gender+Area+Leasing+Fract,
data = base_train,
family=poisson(),
offset = log(Exposure),
method = "REML"
)
model.gam.4 = gam(
Nbclaims ~ s(DriverAge, bs="cr") + Power+Gender+Area+Leasing+Fract + s(CarAge, bs="cr"),
data = base_train,
family=poisson(),
offset = log(Exposure),
method = "REML"
)
model.gam.4 = gam(
Nbclaims ~ s(DriverAge, bs="cr") + Power+Gender+Area+Leasing+Fract + s(CarAge, bs="cr"),
data = base_train,
family=poisson(),
offset = log(Exposure),
method = "REML"
)
models.comparison = addComparison(model.gam.1, "GAM 1")
models.comparison = addComparison(model.gam.2, "GAM 2")
models.comparison = addComparison(model.gam.3, "GAM 3")
models.comparison = addComparison(model.gam.4, "GAM 3")
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10)
)
addComparison(model.tree.1, "Tree 1")
customDeviance(predict(model.tree.1))
1 - pchisq(summary(model.glm.1)$deviance, summary(model.glm.1)$df.residual)
1 - pchisq(summary(model.nb.1)$deviance, summary(model.nb.1)$df.residual)
if (!require(devtools)) install.packages("devtools")
require(devtools)
install_github("fpechon/rfCountData")
install.packages("devtools")
library(rfCountData)
install_github("fpechon/rfCountData")
library(devtools)
Sys.which("make")
if (!require(devtools)) install.packages("devtools")
require(devtools)
install_github("fpechon/rfCountData")
if (!require(devtools)) install.packages("devtools")
require(devtools)
install_github("fpechon/rfCountData")
if (!require(devtools)) install.packages("devtools")
require(devtools)
install_github("fpechon/rfCountData")
devtools::install_github('fpechon/rfCountData')
version
version
update
update()
--update
version()
R.version
devtools::install_github('fpechon/rfCountData')
require(devtools)
install.packages(c("dplyr", "gbm", "ggplot2", "knitr", "mobForest", "pscl", "rpart.plot", "tidyr"))
install.packages(c("caret", "glmnet", "jtools"))
install.packages(c("caret", "glmnet", "jtools"))
Sys.which("make")
Sys.which("make")
install.packages(c("caret", "glmnet", "jtools"))
install.packages(c("caret", "glmnet", "jtools"))
Sys.which("make")
install.packages()
install.packages(all)
base_train_freq$Exposure = ifelse(base_train_freq$Exposure < 1, yes=1, no=base_train_freq$Exposure)
View(base_train_freq)
base_train_freq$Frequency = base_train_freq$Nbclaims / base_train_freq$Exposure
install.packages(c("caret", "glmnet", "jtools"))
install.packages("ggplot2")
pkgbuild::has_build_tools()
pkgbuild::find_rtools()
pkgbuild::find_rtools(debug=T)
pkgbuild::find_rtools(debug = True)
pkgbuild::find_rtools(debug = T)
pkgbuild::find_rtools(debug = TRUE)
pkgbuild::find_rtools(TRUE)
pkgbuild::find_rtools(False)
pkgbuild::find_rtools(F)
pkgconfig::get_config()
pkgbuild::check_rtools()
pkgbuild::check_build_tools()
pkgbuild::compile_dll()
pkgbuild::setup_rtools()
pkgbuild::needs_compile()
install.packages(c("codetools", "KernSmooth", "nlme"))
callr::rcmd_safe("config", "CC")$stdout
install.packages("MASS", type = "source")
file <- tempfile(fileext = ".c")
writeLines("void test() {}", con = file)
R <- file.path(R.home("bin"), "R")
system2(R, c("CMD", "SHLIB", shQuote(file)))
install.packages("MASS", type = "source")
library(MASS) # negative.binomial
library(boot) # GLM CV
library(mgcv) # GAM
library(pscl) # zeroinfl
library(gbm)  # GBM
library(ggplot2)
library(dplyr)
library(tidyr)
library(countreg)
install.packages("countreg")
install.packages(c("caret", "dplyr", "gbm", "ggplot2", "glmnet", "jtools", "knitr", "mobForest", "pscl", "rpart.plot", "tidyr"))
knitr::opts_chunk$set(echo = TRUE)
library(MASS) # negative.binomial
library(boot) # GLM CV
library(mgcv) # GAM
library(pscl) # zeroinfl
library(gbm)  # GBM
library(ggplot2)
library(dplyr)
library(tidyr)
library(countreg)
install.packages("countreg")
library(rpart) # Tree and RF
library(glmnet)
library(jtools)
base_test <- read.table("./data/DBtest.csv", sep=",", header=TRUE)
base_train = read.table("./data/DBtrain.csv", sep=",", header=TRUE)
base_train = within(base_train, {
X = NULL
Gender = factor(Gender, labels=c("M", "F"))
Area = factor(Area, labels=c("Suburban", "Urban", "Countryside low", "Coutryside high"))
Leasing = factor(Leasing, labels=c("Yes", "No"))
Power = factor(Power, labels=c("Low", "Normal", "Intermediate", "High"))
Contract = factor(Contract,  labels=c("Basic", "Intermediate", "Full"))
Fract = factor(Fract, labels=c("Monthly", "Quarterly", "Yearly"))
#Hasclaim = factor(base_train$Nbclaims > 0, labels=c("No", "Yes"))
})
base_train_ordered = within(base_train, {
Power = factor(Power, labels=c("Low", "Normal", "Intermediate", "High"), ordered = T)
Contract = factor(Contract,  labels=c("Basic", "Intermediate", "Full"), ordered = T)
})
base_test = within(base_test, {
X = NULL
Gender = factor(Gender, labels=c("M", "F"))
Area = factor(Area, labels=c("Suburban", "Urban", "Countryside low", "Coutryside high"))
Leasing = factor(Leasing, labels=c("Yes", "No"))
Power = factor(Power, labels=c("Low", "Normal", "Intermediate", "High"))
Contract = factor(Contract, labels=c("Basic", "Intermediate", "Full"))
Fract = factor(Fract, labels=c("Monthly", "Quarterly", "Yearly"))
})
base_test_ordered = within(base_test, {
Power = factor(Power, labels=c("Low", "Normal", "Intermediate", "High"), ordered = T)
Contract = factor(Contract,  labels=c("Basic", "Intermediate", "Full"), ordered = T)
})
base_train_freq = base_train
base_train_freq$Frequency = base_train$Nbclaims / base_train$Exposure
base_train_nonull = base_train[base_train$Nbclaims > 0,]
# Custom breaks for GLM. We'll use GAM later.
glm_train = base_train
glm_test = base_test
glm_break_driver = c(18,25,35,50,65,80,100) # 6
glm_break_car = c(0,3,6,9,12,15,20) # 6
glm_train$DriverAge <- cut(glm_train$DriverAge, breaks = glm_break_driver, right=F)
glm_test$DriverAge <- cut(glm_test$DriverAge, breaks = glm_break_driver, right=F)
glm_train$CarAge <- cut(glm_train$CarAge, breaks = glm_break_car, right = F)
glm_test$CarAge <- cut(glm_test$CarAge, breaks = glm_break_car, right = F)
# ---
formule.covariates = c("Gender", "DriverAge", "CarAge", "Area", "Leasing", "Power", "Fract", "Contract")
formule.long.offset = as.formula(paste("Nbclaims ~ offset(log(Exposure)) + ", paste(formule.covariates, collapse=" + ")))
formule.long = as.formula(paste("Nbclaims ~ ", paste(formule.covariates, collapse=" + ")))
formule.step = as.formula(Nbclaims ~ Gender + DriverAge + Area + Leasing +
Power + Fract + offset(log(Exposure)))
customDeviance = function(fitt){
y = base_train_freq$Frequency
w = base_train$Exposure
left = y * log(y) - y * log(fitt)
right = y - fitt
left[y==0] = 0 # Replace NA's by 0 because log(0) is -Inf but 0*Inf ~ 0
return(2*sum(w*(left-right)))
}
models.comparison = data.frame()
addComparison = function(model, model_name){
to_combine = data.frame(
LogLik = logLik(model)[1],
AIC = AIC(model),
BIC = BIC(model),
#Deviance = deviance(model)|0,
Deviance.custom = customDeviance(model$fitted),
#Percent.of.zero = round(mean(exp(-exp(predict(model))))*100,2),
#Range.Predict = range(exp(predict(model))),
Count.0 = round(sum(dpois(0, model$fitted))),
Count.1 = round(sum(dpois(1, model$fitted))),
Count.2 = round(sum(dpois(2, model$fitted))),
Count.3 = round(sum(dpois(3, model$fitted))),
Count.4 = round(sum(dpois(4, model$fitted))),
row.names = as.character(model_name)
)
rbind(
models.comparison,
to_combine
)
}
model.nb.1 = glm.nb(formule.long.offset, data = base_train, control = glm.control(trace = 2, maxit = 100))
model.nb.2= glm.nb(formule.long, data = base_train, offset=log(Exposure))
model.nb.2= glm.nb(formule.long, data = base_train)
model.nb.2= glm.nb(formule.long.offset, data = base_train)
glm(formule.long.offset, data=base_train, family=negative.binomial())
glm(formule.long.offset, data=base_train, family=negative.binomial(1))
model.glm.nb = glm(formule.long.offset, data=base_train, family=negative.binomial(1))
summary(model.glm.nb)$thetha
summary(model.nb.2)$thetha
model.nb.2= glm.nb(formule.step, data = base_train)
model.nb.2= glm.nb(formule.step, data = base_train, control = glm.control(trace = 2, maxit = 100))
model.nb.2= glm.nb(formule.long, data = base_train, control = glm.control(trace = 2, maxit = 100))
summary(model.nb.2)$theta
dbinom(0, mu=predict(model.nb.2, type="response"), size=4.785021)
dnbinom(0, mu=predict(model.nb.2, type="response"), size=4.785021)
sum(dnbinom(0, mu=predict(model.nb.2, type="response"), size=4.785021))
range(dnbinom(0, mu=predict(model.nb.2, type="response"), size=4.785021))
range(dnbinom(1, mu=predict(model.nb.2, type="response"), size=4.785021))
sum(dnbinom(1, mu=predict(model.nb.2, type="response"), size=4.785021))
sum(dnbinom(2, mu=predict(model.nb.2, type="response"), size=4.785021))
sum(dnbinom(3, mu=predict(model.nb.2, type="response"), size=4.785021))
deviance(model.nb.2)
customDeviance(model.nb.2)
customDeviance(model.nb.2$fitted.values)
model.glm.1 = glm(formule.long.offset, data = base_train, family=quasipoisson(link = "log"))
model.glm.2 = glm(formule.long.offset, data = base_train, family="poisson")
model.zero.1 = zeroinfl(formule.long.offset, data=base_train, dist="negbin")
model.zero.2 = zeroinfl(formule.long, data=glm_train, dist="negbin", offset = log(Exposure))
model.zero.2 = zeroinfl(formule.long, data=glm_train, dist="negbin", offset = log(Exposure))
model.hurdle.1 = hurdle(formule.long.offset, data=base_train, dist="poisson",
zero.dist = "")
model.hurdle.1 = hurdle(formule.long.offset, data=base_train, dist="negbin", zero.dist = "poisson")
install.packages("countreg")
install.packages("countreg", available = T)
install.packages("countreg", repos="http://R-Forge.R-project.org")
library(countreg)
rootogram(model.hurdle.1)
summary(model.hurdle.1)
hurdletest(model.hurdle.1)
model.hurdle.1$fitted.values
range(model.hurdle.1$fitted.values)
range(exp(model.hurdle.1$fitted.values)-
0)
model.hurdle.1$theta
fitdistr(base_train$Nbclaims, dpois)
?fitdistr
fitdistr(base_train$Nbclaims, "Oiussib")
fitdistr(base_train$Nbclaims, "Poisson")
fitdistr(base_train$Nbclaims, "negative binomial")
fitdistr(base_train$Nbclaims, "negative lognormal")
fitdistr(base_train$Nbclaims, "lognormal")
fitdistr(base_train$Nbclaims, "gamma")
fitdistr(base_train$Nbclaims, "geometric")
fitdistr(base_train$Nbclaims, "Poisson")$loglik
summary(fitdistr(base_train$Nbclaims, "Poisson"))
fitdistr(base_train$Nbclaims, "Poisson")[,]
fitdistr(base_train$Nbclaims, "Poisson")[1:4]
fitdistr(base_train$Nbclaims, "negative binomial")[1:4]
if (!require(devtools)) install.packages("devtools")
require(devtools)
install_github("fpechon/rfCountData")
fitdistr(base_train$Nbclaims, "Poisson")[1:6]
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 10)
)
rpart.plot(model.tree.1)
library(rpart.plot)
rpart.plot(model.tree.1)
predict(model.tree.1)
range(predict(model.tree.1))
range(exp(predict(model.tree.1)))
printcp(model.tree.1)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.005, xval = 10, maxdepth = 10)
)
printcp(model.tree.1)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 20)
)
printcp(model.tree.1)
rpart.plot(model.tree.1)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train_ordered,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 20)
)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train_ordered,
method = "poisson",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 20)
)
rpart.plot(model.tree.1)
rpart.plot(model.tree.1)
install_github("fpechon/rfCountData")
pkgbuild::check_build_tools(debug = TRUE)
pkgbuild::check_build_tools(debug = TRUE)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train_ordered,
method = "negative binomial",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 20)
)
# Factors are ordered
model.tree.1 = rpart(
cbind(Exposure, Nbclaims) ~ Gender + DriverAge + CarAge + Power + Area + Fract + Leasing,
data=base_train_ordered,
method = "negbin",
parms = list(shrink=4), # Method is deviance
control = rpart.control(cp = 0.0005, xval = 10, maxdepth = 20)
)
install_github("fpechon/rfCountData")
library(rfCountData)
?rfPoisson
rfPoisson_train = within(base_train, {
Nbclaims = NULL
Exposure = NULL
})
View(rfPoisson_train)
rfCountData::rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=1000, nodesize=5000, do.trace=T)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=1000, nodesize=5000, do.trace=T)
model.rfCount$oob.times
model.rfCount$test
?rfPoisson
predict(model.rfCount, type = "response")
range(predict(model.rfCount, type = "response"))
summary(predict(model.rfCount, type = "response"))
exp(predict(model.rfCount, type = "response"))
range(exp(predict(model.rfCount, type = "response")))
View(base_train_freq)
base_train_freq$Exposure = ifelse(base_train$Exposure < 1, yes=1, no=base_train$Exposure)
base_train_freq$Frequency = base_train$Nbclaims + base_train_freq$Exposure
base_train_freq$Frequency = base_train$Nbclaims / base_train_freq$Exposure
rfPoisson_train = within(base_train_freq, {
Nbclaims = NULL
Exposure = NULL
})
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=500, nodesize=5000, do.trace=T)
model.rfCount$ntree
predict(model.rfCount)
range(predict(model.rfCount))
range(exp(predict(model.rfCount)))
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=50, nodesize=1, do.trace=T)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=50, nodesize=1, maxnodes=15, do.trace=T)
range(predict(model.rfCount))
frame.test = data.frame(base_train_freq, Predicted=predict(model.rfCount))
View(frame.test)
rfPoisson_train = within(base_train, {
Nbclaims = NULL
Exposure = NULL
})
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=50, nodesize=1, maxnodes=15, do.trace=T)
rpart.plot(model.rfCount)
range(predict(model.rfCount))
rfPoisson_train = within(base_train_freq, {
Nbclaims = NULL
Exposure = NULL
})
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=1, maxnodes=15, do.trace=T)
frame.test = data.frame(base_train, Frequency=base_train$Nbclaims/base_train$Exposure, Predicted=predict(model.rfCount))
frame.test$Difference = frame.test$Frequency - frame.test$Predicted
View(frame.test)
sum(frame.test$Difference)
sum(abs(frame.test$Difference))
sum(abs(frame.test$Difference))/70000
sum(frame.test$Frequency)
sum(frame.test$Predicted)
rfPoisson_train = within(base_train_freq, {
Nbclaims = NULL
Exposure = NULL
Frequency = NULL
})
View(rfPoisson_train)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=1, maxnodes=15, do.trace=T)
frame.test = data.frame(base_train, Frequency=base_train$Nbclaims/base_train$Exposure, Predicted=predict(model.rfCount))
frame.test$Difference = frame.test$Frequency - frame.test$Predicted
range(frame.test$Predicted)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=1, maxnodes=50, do.trace=T)
frame.test = data.frame(base_train, Frequency=base_train$Nbclaims/base_train$Exposure, Predicted=predict(model.rfCount))
frame.test$Difference = frame.test$Frequency - frame.test$Predicted
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=9, maxnodes=50, do.trace=T, replace = F)
range(predict(model.rfCount))
range(predict(model.tree.1))
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=2, maxnodes=150, do.trace=T, replace = F)
install.packages("JWileymisc")
install.packages("JWileymisc")
library(JWileymisc)
testDistribution()
?testDistribution
testDistribution(base_train$Nbclaims, distr="poisson")
testDistrib = testDistribution(base_train$Nbclaims, distr="poisson")
testDistrib$Data
testDistrib$Data[65000:65050]
testDistrib$Data[69900:]
testDistrib$Data[69900:70000]
testDistrib$Data[69900:69950]
testDistrib = testDistribution(base_train$Nbclaims/base_train$Exposure, distr="poisson")
warnings()
testDistrib = testDistribution(base_train$Nbclaims, distr="nbinom")
testDistrib
testDistrib = testDistribution(base_train$Nbclaims, distr="gamma")
testDistrib = testDistribution(base_train$Nbclaims, distr="geometric")
testDistrib
??fitdist
library(MASS)
knitr::opts_chunk$set(echo = TRUE)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=10000, maxnodes=150, do.trace=T, replace = F)
library(rfCountData)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=10000, maxnodes=150, do.trace=T, replace = F)
rfPoisson_train = within(base_train, {
Nbclaims = NULL
Exposure = NULL
Frequency = NULL
})
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=1, maxnodes=30, do.trace=T, replace = F)
model.rfCount = rfPoisson(x = rfPoisson_train, y=base_train$Nbclaims, offset = log(base_train$Exposure),
ntree=100, nodesize=1, maxnodes=30, do.trace=T, replace = T)
boxplot(base_train_freq$Frequency)
boxplot(base_train_nonull$Frequency)
boxplot(base_train_nonull$Nbclaims)
